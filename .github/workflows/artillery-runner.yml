name: "Artillery Load Test"

run-name: >
  Artillery Workflow: ${{ github.event.inputs.test_name }} ${{ github.event.inputs.run_name }}
  
# ============================================================
# PURPOSE:
# This workflow automates load testing using Artillery for multiple
# applications and environments (test/prod). It can:
#  - Run parallel tests across multiple GitHub runners
#  - Aggregate results and generate dashboards
#  - Clean up old reports/artifacts when requested
# ============================================================

# ============================================================
# Trigger: Manual dispatch via GitHub UI with input parameters
# ============================================================
on:
  workflow_dispatch:
    inputs:
      test_type:
        description: "Choose test type: 'load' to run tests, or 'cleanup' to delete old reports/artifacts"
        required: true
        type: choice
        options:
          - load
          - cleanup

      environment_name:
        description: "Select environment (test or prod)"
        required: true
        type: choice
        options:
          - test
          - prod

      app_name:
        description: "Application to test (e.g., app1, app2)"
        required: true
        type: choice
        options:
          - app1
          - app2

      runners_to_use:
        description: "Number of parallel runners to use (1â€“4)"
        required: true
        type: choice
        options:
          - '1'
          - '2'
          - '3'
          - '4'

      scenario_file:
        description: "YAML file for Artillery scenario (e.g., loadtest.yml)"
        required: true
        default: "aws_signed_api.yml ,aws_api.yml"

      test_name:
        description: "Optional test name (blank = auto-generated)"
        required: false
        default: ""

      run_name:
        description: "Optional run name (blank = auto-generated)"
        required: false
        default: ""

      monitor_system:
        description: "Enable runner CPU/memory monitoring during tests?"
        required: false
        type: choice
        options:
          - "true"
          - "false"
        default: "false"

      cleanup_days:
        description: "Delete reports/artifacts older than X days (used in cleanup mode)"
        required: false
        default: "7"

      print_machine_info:
        description: "Print machine details before running?"
        required: false
        type: choice
        options:
          - "true"
          - "false"
        default: "false"

# ============================================================
# Global environment variables used throughout all jobs
# ============================================================
env:
  ARTILLERY_VERSION: "2.0.21"
  UPLOAD_RESULTS: "true"
  SCRIPTS_DIR: "./applications/${{ github.event.inputs.app_name }}/scripts"
  DATA_DIR: "./applications/${{ github.event.inputs.app_name }}/data"

  # -------------------------------
  # Variables for Python script environment (Requirement 2)
  # -------------------------------
  PY_APP_NAME: ${{ github.event.inputs.app_name }}
  PY_TEST_NAME: ${{ github.event.inputs.test_name }}        
  PY_RUN_ID: ${{ github.event.inputs.run_name }}            
  PY_SLA: ""                                               
  PY_MODE: ""                                              
  PY_GRANULARITY: ""                                       
  PY_SHOW_OVERALL_METRICS: ""                              


# ============================================================
# JOB 1: Set test name dynamically
# ============================================================
jobs:
  set-test-name:
    runs-on: ubuntu-latest
    outputs:
      final_test_name: ${{ steps.determine.outputs.final_test_name }}

    steps:
      - id: determine
        run: |
          # ----------------------------------------------------
          # Dynamically build the test name using inputs
          # ----------------------------------------------------
          DATE_MMDDYYYY=$(date +%m%d%Y)
          DATE_YYYYMMDD=$(date +%Y%m%d)
          BASE_NAME="artillery"

          # Construct name based on which inputs are given
          if [ -n "${{ github.event.inputs.test_name }}" ] && [ -n "${{ github.event.inputs.run_name }}" ]; then
            FINAL_NAME="${BASE_NAME}-${{ github.event.inputs.test_name }}-${{ github.event.inputs.run_name }}"
          elif [ -n "${{ github.event.inputs.test_name }}" ]; then
            FINAL_NAME="${BASE_NAME}-${{ github.event.inputs.test_name }}"
          elif [ -n "${{ github.event.inputs.run_name }}" ]; then
            FINAL_NAME="${BASE_NAME}-${{ github.event.inputs.run_name }}"
          else
            FINAL_NAME="${BASE_NAME}-test-${DATE_YYYYMMDD}-run_${DATE_MMDDYYYY}"
          fi

          echo "âœ… Final test name: $FINAL_NAME"
          echo "final_test_name=$FINAL_NAME" >> $GITHUB_OUTPUT

# ============================================================
# JOB 2: Run Artillery tests in parallel (if test_type == load)
# ============================================================
  run-artillery:
    if: ${{ github.event.inputs.test_type == 'load' }}
    name: "Run Artillery Tests"
    runs-on: ubuntu-latest
    needs: set-test-name

    # Use environment-specific secrets/variables (test/prod)
    environment: ${{ github.event.inputs.environment_name }}

    strategy:
      fail-fast: false
      matrix:
        runner_index: [1, 2, 3, 4]

    steps:
      # -------------------------------
      # Set REPORT_DIR using the output from the set-test-name job (Fix for Error)
      # -------------------------------
      - name: Set job environment variables
        id: set_env
        run: |
          echo "REPORT_DIR=./reports/${{ github.event.inputs.app_name }}/${{ needs.set-test-name.outputs.final_test_name }}" >> $GITHUB_ENV

          
      # -----------------------------
      # Skip unused runners
      # -----------------------------
      - name: Skip Unused Runner
        if: ${{ matrix.runner_index > fromJSON(github.event.inputs.runners_to_use) }}
        run: |
          echo "Skipping runner ${{ matrix.runner_index }}"
          exit 0

      # -----------------------------
      # Checkout source code
      # -----------------------------
      - uses: actions/checkout@v4

      # -----------------------------
      # Optional: Print runner details
      # -----------------------------
      - name: Print Machine Info
        if: ${{ github.event.inputs.print_machine_info == 'true' }}
        run: |
          echo "===== Machine Info ====="
          nproc
          free -h
          uname -a
          echo "========================"

      # -------------------------------
      # Setup Python environment
      # -------------------------------
      - name: Setup Python
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        uses: actions/setup-python@v5
        with:
          python-version: "3.13.1"

      # -------------------------------
      # Install Python dependencies
      # -------------------------------
      - name: Install Python Dependencies
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        run: |
          python -m pip install --upgrade pip
          pip install pandas plotly numpy pyyaml

      # -------------------------------
      # Ensure scenario YAML exists
      # -------------------------------
      - name: Check scenario YAML exists
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        shell: bash
        run: |
          if [ ! -f "${{ env.SCRIPTS_DIR }}/${{ github.event.inputs.scenario_file }}" ]; then
            echo "Scenario file not found!"
            exit 1
          else
            echo "Found scenario file: ${{ env.SCRIPTS_DIR }}/${{ github.event.inputs.scenario_file }}"
          fi
          
      # -----------------------------
      # Setup Node.js environment
      # -----------------------------
      - name: Setup Node.js
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        uses: actions/setup-node@v4
        with:
          node-version: 20

      # -----------------------------
      # Install Artillery globally
      # -----------------------------
      - name: Install Artillery
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        run: |
          npm install -g artillery@${{ env.ARTILLERY_VERSION }}
          npm install aws4 @faker-js/faker csv-parse
          npm install --save-dev artillery-plugin-metrics-by-endpoint
          artillery --version

      # -------------------------------
      # Optional System Monitoring
      # -------------------------------
      - name: Start system monitoring (optional)
        if: ${{ github.event.inputs.monitor_system == 'true' && matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        shell: bash
        run: |
          mkdir -p "${{ env.REPORT_DIR }}"
          LOG_FILE="${{ env.REPORT_DIR }}/runner-${{ matrix.runner_index }}-system.log"
          echo "timestamp,cpu_user,cpu_system,cpu_idle,mem_used,mem_free" > $LOG_FILE
          monitor() {
            while true; do
              ts=$(date +"%Y-%m-%d %H:%M:%S")
              cpu=$(mpstat 1 1 | awk '/Average/ {print $3","$5","$12}')
              mem=$(free -m | awk '/Mem:/ {print $3","$4}')
              echo "$ts,$cpu,$mem" >> $LOG_FILE
              sleep 180
            done
          }
          monitor &
          echo $! > /tmp/monitor_pid.txt
          echo "System monitoring started in background, logging every 5 minutes."
          
      # -----------------------------
      # Map Environment Variables 
      # -----------------------------
      - name: Map Environment Variables Dynamically
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        shell: bash
        env:
          # Define the dynamic variables for the next step's script
          APP_UPPER: ${{ github.event.inputs.app_name }} # Pass app_name to the shell
          # Expose the values of the variables/secrets
          # NOTE: The names here must be exactly what is set in the environment 'test' or 'prod'
          APP_BASE_URL: ${{ vars[format('{0}_BASE_URL', github.event.inputs.app_name)] }}
          APP_TARGET_HOST: ${{ vars[format('{0}_TARGET_HOST', github.event.inputs.app_name)] }}
          APP_REGION: ${{ vars[format('{0}_REGION', github.event.inputs.app_name)] }}
          APP_ACCESS_KEY: ${{ secrets[format('{0}_ACCESS_KEY', github.event.inputs.app_name)] }}
          APP_SECRET_KEY: ${{ secrets[format('{0}_SECRET_KEY', github.event.inputs.app_name)] }}
        run: |
          # Convert app_name input to uppercase (e.g., "app1" -> "APP1")
          APP_UPPER=$(echo "$APP_UPPER" | tr '[:lower:]' '[:upper:]')
          
          # Use the environment variables set in the 'env:' block above
          BASE_URL="${APP_BASE_URL}"
          TARGET_HOST="${APP_TARGET_HOST}"
          AWS_REGION="${APP_REGION}"
          AWS_ACCESS_KEY_ID="${APP_ACCESS_KEY}"
          AWS_SECRET_ACCESS_KEY="${APP_SECRET_KEY}"
          
          # Export to GitHub Actions environment for subsequent steps
          echo "BASE_URL=$BASE_URL" >> $GITHUB_ENV
          echo "TARGET_HOST=$TARGET_HOST" >> $GITHUB_ENV
          echo "AWS_REGION=$AWS_REGION" >> $GITHUB_ENV
          echo "AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY" >> $GITHUB_ENV # NOTE: GitHub automatically masks secrets in logs
          
          echo "âœ… Environment variables mapped for $APP_UPPER"
          echo "BASE_URL=$BASE_URL"
          echo "TARGET_HOST=$TARGET_HOST"
          echo "REGION=$REGION"
          
      # -----------------------------
      # Run Artillery Test
      # -----------------------------
      - name: Run Artillery Test
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        id: run_test
        shell: bash
        env:
          AUTH_HEADER: ${{ secrets.AUTH_HEADER }}
        run: |
          # Prepare directories
          REPORT_DIR="./reports/${{ github.event.inputs.app_name }}/${{ needs.set-test-name.outputs.final_test_name }}"
          mkdir -p "$REPORT_DIR"

          # Construct output filenames
          JSON_OUT="$REPORT_DIR/result-runner-${{ matrix.runner_index }}.json"
          HTML_OUT="$REPORT_DIR/result-runner-${{ matrix.runner_index }}.html"

          echo "ðŸš€ Running Artillery for ${{ github.event.inputs.app_name }} on environment: ${{ github.event.inputs.environment_name }}"
          echo "ðŸ”— Target URL: $BASE_URL"

          # Run test using environment secrets & vars
          BASE_URL="$BASE_URL" \
          API_KEY="$API_KEY" \
          TARGET_HOST="$TARGET_HOST" \
          AUTH_HEADER="$AUTH_HEADER" \
          AWS_REGION="$AWS_REGION" \
          AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID" \
          AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY" \
          npx artillery run "applications/${{ github.event.inputs.app_name }}/scripts/${{ github.event.inputs.scenario_file }}" \
            --output "$JSON_OUT"

          # Generate HTML report
          npx artillery report "$JSON_OUT" --output "$HTML_OUT"

          echo "âœ… Artillery reports generated at: $REPORT_DIR"

      # -------------------------------
      # Stop system monitoring (optional)
      # -------------------------------
      - name: Stop system monitoring (optional)
        if: ${{ github.event.inputs.monitor_system == 'true' && matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        shell: bash
        run: |
          if [ -f /tmp/monitor_pid.txt ]; then
            kill $(cat /tmp/monitor_pid.txt) || true
            rm /tmp/monitor_pid.txt
            echo "System monitoring stopped."
          fi
      # -------------------------------
      # Upload system monitoring logs (optional)
      # -------------------------------
      - name: Upload system monitoring logs (optional)
        if: ${{ github.event.inputs.monitor_system == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: runner-${{ matrix.runner_index }}-system-logs
          path: ${{ env.REPORT_DIR }}/runner-${{ matrix.runner_index }}-system.log


      # -------------------------------
      # Generate Python dashboard for this runner (Requirement 2)
      # -------------------------------
      - name: Generate Python dashboard for this runner
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        continue-on-error: true
        shell: bash
        run: |
          # Define per-runner subfolder under REPORT_DIR
          RUNNER_DIR="${{ env.REPORT_DIR }}/runner-${{ matrix.runner_index }}"
          mkdir -p "$RUNNER_DIR"

          # Define dashboard HTML output
          RUNNER_HTML="$RUNNER_DIR/runner-${{ matrix.runner_index }}-dashboard.html"
          echo "ðŸ“Š Generating Python dashboard for runner ${{ matrix.runner_index }}..."
          
          # Build dynamic arguments for the Python script
          ARGS=""
          if [ -n "${{ env.PY_APP_NAME }}" ]; then
            ARGS="$ARGS --app-name \"${{ env.PY_APP_NAME }}\""
          fi
          if [ -n "${{ env.PY_TEST_NAME }}" ]; then
            ARGS="$ARGS --test-name \"${{ env.PY_TEST_NAME }}\""
          fi
          if [ -n "${{ env.PY_SLA }}" ]; then
            ARGS="$ARGS --sla \"${{ env.PY_SLA }}\""
          fi
          if [ -n "${{ env.PY_MODE }}" ]; then
            ARGS="$ARGS --mode \"${{ env.PY_MODE }}\""
          fi
          if [ -n "${{ env.PY_GRANULARITY }}" ]; then
            ARGS="$ARGS --granularity \"${{ env.PY_GRANULARITY }}\""
          fi
          if [ -n "${{ env.PY_SHOW_OVERALL_METRICS }}" ]; then
            ARGS="$ARGS --show-overall-metrics"
          fi

          # Run the Python dashboard generator for this runner
          python "${GITHUB_WORKSPACE}/utilities/generate_artillery_dashboard.py" \
            --json "${{ env.REPORT_DIR }}/${{ steps.run_test.outputs.result_json }}" \
            --yaml "${{ env.SCRIPTS_DIR }}/${{ github.event.inputs.scenario_file }}" \
            --output "$RUNNER_HTML" \
            $ARGS || echo "âš ï¸ Python dashboard generation failed for runner ${{ matrix.runner_index }} (non-blocking)."

          echo "âœ… Dashboard generated for runner ${{ matrix.runner_index }} (if successful): $RUNNER_HTML"


      # -------------------------------
      # Package Artillery results, dashboards, and logs into ZIP
      # -------------------------------
      - name: Package all runner results into ZIP
        if: always()
        shell: bash
        run: |
          RUNNER_DIR="${{ env.REPORT_DIR }}/runner-${{ matrix.runner_index }}"
          ZIP_NAME="runner-${{ matrix.runner_index }}-results.zip"
          UPLOAD_DIR="upload"
          mkdir -p "$UPLOAD_DIR"

          echo "ðŸ“¦ Packaging files for runner ${{ matrix.runner_index }}..."
          
          # Include JSON, HTML, CPU/memory logs, and anything else in runner folder
          zip -r "$UPLOAD_DIR/$ZIP_NAME" "$RUNNER_DIR" >/dev/null || echo "âš ï¸ ZIP packaging encountered a warning"

          echo "âœ… Packaged runner ZIP: $UPLOAD_DIR/$ZIP_NAME"


      # -------------------------------
      # Upload runner artifact
      # -------------------------------
      - name: Upload runner artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: artillery-results-runner-${{ matrix.runner_index }}
          path: upload/runner-${{ matrix.runner_index }}-results.zip
        continue-on-error: true
          
# ============================================================
# JOB 3: Aggregate results after all runners finish
# ============================================================
  aggregate-reports:
    if: always()
    name: "Aggregate & Upload Final Reports"
    runs-on: ubuntu-latest
    needs: [set-test-name, run-artillery]

    steps:
      # -------------------------------
      # Set REPORT_DIR for this job
      # -------------------------------
      - name: Set job environment variables
        id: set_env
        run: |
          REPORT_DIR="./reports/${{ github.event.inputs.app_name }}/${{ needs.set-test-name.outputs.final_test_name }}"
          echo "REPORT_DIR=$REPORT_DIR" >> $GITHUB_ENV
          echo "âœ… REPORT_DIR set to: $REPORT_DIR"

      # -------------------------------
      # Checkout repository
      # -------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # -------------------------------
      # Download all runner artifacts
      # -------------------------------
      - name: Download all runner artifacts
        uses: actions/download-artifact@v4
        with:
          path: artillery-results
        continue-on-error: true

      # -------------------------------
      # Extract all runner ZIPs
      # -------------------------------
      - name: Extract all runner ZIPs
        shell: bash
        run: |
          mkdir -p combined-results
          for zipfile in artillery-results/**/*.zip; do
            [ -f "$zipfile" ] || continue
            foldername=$(basename "$zipfile" .zip)
            echo "ðŸ“¦ Extracting $zipfile -> combined-results/$foldername"
            mkdir -p combined-results/"$foldername"
            unzip -o "$zipfile" -d combined-results/"$foldername" >/dev/null
          done
          echo "âœ… Extraction complete."

      # -------------------------------
      # Copy only JSON & HTML files to REPORT_DIR
      # -------------------------------
      - name: Copy JSON & HTML to REPORT_DIR
        shell: bash
        run: |
          echo "ðŸ“ Copying JSON and HTML files to REPORT_DIR..."
          mkdir -p "${{ env.REPORT_DIR }}"
          for runner_folder in combined-results/*; do
            if [ -d "$runner_folder" ]; then
              cp "$runner_folder"/*.json "${{ env.REPORT_DIR }}/" 2>/dev/null || true
              cp "$runner_folder"/*.html "${{ env.REPORT_DIR }}/" 2>/dev/null || true
            fi
          done
          echo "âœ… JSON and HTML files copied to ${{ env.REPORT_DIR }}"
          
      # -------------------------------
      # Determine test name for consolidated files
      # -------------------------------
      - name: Determine test name
        id: test_name
        shell: bash
        run: |
          CONSOLIDATED_NAME="${{ needs.set-test-name.outputs.final_test_name }}"
          echo "consolidated_test_name=$CONSOLIDATED_NAME" >> $GITHUB_OUTPUT
          echo "âœ… Using consolidated test name: $CONSOLIDATED_NAME"

      # -------------------------------
      # Collect all JSON filenames
      # -------------------------------
      - name: Collect all JSON filenames
        id: collect_jsons
        shell: bash
        run: |
          JSON_FILES=$(find combined-results -name '*.json' -type f | paste -sd "," -)
          if [ -z "$JSON_FILES" ]; then
            echo "âš ï¸ No JSON files found. Skipping final dashboard generation."
            echo "json_files=" >> $GITHUB_OUTPUT
            exit 0
          fi
          echo "json_files=$JSON_FILES" >> $GITHUB_OUTPUT
          echo "âœ… Found JSON files: $JSON_FILES"

      # -------------------------------
      # Setup Python for consolidation
      # -------------------------------
      - name: Setup Python
        if: ${{ steps.collect_jsons.outputs.json_files != '' }}
        uses: actions/setup-python@v5
        with:
          python-version: "3.13.1"

      - name: Install Python Dependencies
        if: ${{ steps.collect_jsons.outputs.json_files != '' }}
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyyaml plotly numpy

      # -------------------------------
      # Generate consolidated Python dashboard
      # -------------------------------
      - name: Generate consolidated Python dashboard
        if: ${{ steps.collect_jsons.outputs.json_files != '' }}
        shell: bash
        continue-on-error: true
        run: |
          FINAL_HTML="${{ steps.test_name.outputs.consolidated_test_name }}-consolidated-dashboard.html"
          ARGS=""

          if [ -n "${{ env.PY_APP_NAME }}" ]; then
            ARGS="$ARGS --app-name \"${{ env.PY_APP_NAME }}\""
          fi
          if [ -n "${{ env.PY_TEST_NAME }}" ]; then
            ARGS="$ARGS --test-name \"${{ env.PY_TEST_NAME }}\""
          fi
          if [ -n "${{ env.PY_SLA }}" ]; then
            ARGS="$ARGS --sla \"${{ env.PY_SLA }}\""
          fi
          if [ -n "${{ env.PY_MODE }}" ]; then
            ARGS="$ARGS --mode \"${{ env.PY_MODE }}\""
          fi
          if [ -n "${{ env.PY_GRANULARITY }}" ]; then
            ARGS="$ARGS --granularity \"${{ env.PY_GRANULARITY }}\""
          fi
          if [ -n "${{ env.PY_SHOW_OVERALL_METRICS }}" ]; then
            ARGS="$ARGS --show-overall-metrics"
          fi

          echo "ðŸ§  Generating consolidated Python dashboard..."
          python "${GITHUB_WORKSPACE}/utilities/generate_artillery_dashboard.py" \
            --json "${{ steps.collect_jsons.outputs.json_files }}" \
            --yaml "${{ env.SCRIPTS_DIR }}/${{ github.event.inputs.scenario_file }}" \
            --output "$FINAL_HTML" \
            $ARGS || echo "âš ï¸ Python consolidation failed, continuing."

          echo "âœ… Consolidated Python dashboard generated: $FINAL_HTML"

      # -------------------------------
      # Package consolidated artifacts
      # -------------------------------
      - name: Package consolidated artifacts
        shell: bash
        run: |
          mkdir -p final-upload

          # Copy all extracted runner zips, dashboards, logs, and final HTML
          cp artillery-results/**/*.zip final-upload/ 2>/dev/null || true
          cp combined-results/**/*.html final-upload/ 2>/dev/null || true
          cp combined-results/**/*.log final-upload/ 2>/dev/null || true
          cp *.html final-upload/ 2>/dev/null || true

          # Archive everything into a single consolidated ZIP
          zip -r "consolidated-results.zip" final-upload/ >/dev/null
          echo "âœ… Packaged all results into consolidated-results.zip"

      # -------------------------------
      # Upload consolidated artifacts as GitHub artifact
      # -------------------------------
      - name: Upload consolidated artifacts
        uses: actions/upload-artifact@v4
        with:
          name: consolidated-artillery-results
          path: consolidated-results.zip

      # -------------------------------
      # Upload consolidated artifact to results folder (flag-based)
      # -------------------------------
      - name: Upload consolidated results to results folder
        if: ${{ env.UPLOAD_RESULTS == 'true' }}
        shell: bash
        run: |
          FINAL_RESULTS_DIR="./reports/${{ github.event.inputs.app_name }}/${{ steps.test_name.outputs.consolidated_test_name }}"
          mkdir -p "$FINAL_RESULTS_DIR"
          cp consolidated-results.zip "$FINAL_RESULTS_DIR/"
          echo "âœ… Consolidated results uploaded to $FINAL_RESULTS_DIR"

# ============================================================
# JOB 4: Cleanup (Only deletes old reports and artifacts)
# ============================================================
  cleanup-artifacts:
    if: ${{ github.event.inputs.test_type == 'cleanup' }}
    name: "Cleanup Old Reports & Artifacts"
    runs-on: ubuntu-latest
    permissions:
      actions: write

    steps:
      - uses: actions/checkout@v4

      # -----------------------------
      # Delete old local reports
      # -----------------------------
      - name: Delete Old Local Reports
        run: |
          REPORT_DIR="./reports/${{ github.event.inputs.app_name }}"
          DAYS=${{ github.event.inputs.cleanup_days }}
          echo "ðŸ§¹ Deleting local reports older than $DAYS days from $REPORT_DIR"
          find "$REPORT_DIR" -type f \( -name '*.json' -o -name '*.html' -o -name '*.zip' \) -mtime +$DAYS -print -delete
          echo "âœ… Local report cleanup completed."

      # -----------------------------
      # Delete old GitHub Actions artifacts
      # -----------------------------
      - name: Delete Old GitHub Artifacts
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          DAYS=${{ github.event.inputs.cleanup_days }}
          echo "ðŸ§¹ Deleting GitHub Actions artifacts older than $DAYS days..."

          ARTIFACTS=$(curl -s -H "Authorization: token $GITHUB_TOKEN" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts?per_page=100" \
            | jq -r '.artifacts[] | "\(.id) \(.created_at)"')

          NOW=$(date +%s)
          while read -r ID CREATED_AT; do
            ART_TS=$(date -d "$CREATED_AT" +%s)
            AGE=$(( (NOW - ART_TS) / 86400 ))
            if [ "$AGE" -gt "$DAYS" ]; then
              echo "Deleting artifact ID: $ID (created $CREATED_AT, $AGE days old)"
              curl -s -X DELETE -H "Authorization: token $GITHUB_TOKEN" \
                "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ID"
            fi
          done <<< "$ARTIFACTS"

          echo "âœ… GitHub artifact cleanup completed."
