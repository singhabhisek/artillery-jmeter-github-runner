name: "Artillery Load Test"

run-name: >
  Artillery Workflow: ${{ github.event.inputs.test_name }} ${{ github.event.inputs.run_name }}

# ============================================================
# PURPOSE:
# This workflow automates load testing using Artillery for multiple
# applications and environments (test/prod). It can:
#  - Run parallel tests across multiple GitHub runners
#  - Aggregate results and generate dashboards
#  - Clean up old reports/artifacts when requested
# ============================================================

# ============================================================
# Trigger: Manual dispatch via GitHub UI with input parameters
# ============================================================
on:
  workflow_dispatch:
    inputs:
      test_type:
        description: "Choose test type: 'load' to run tests, or 'cleanup' to delete old reports/artifacts"
        required: true
        type: choice
        options:
          - load
          - cleanup

      environment_name:
        description: "Select environment (test or prod)"
        required: true
        type: choice
        options:
          - test
          - prod

      app_name:
        description: "Application to test (e.g., app1, app2)"
        required: true
        type: choice
        options:
          - app1
          - app2

      runners_to_use:
        description: "Number of parallel runners to use (1â€“4)"
        required: true
        type: choice
        options:
          - '1'
          - '2'
          - '3'
          - '4'

      scenario_file:
        description: "YAML file(s) for Artillery scenario (e.g., loadtest.yml or file1.yml,file2.yml)"
        required: true
        default: "aws_signed_api.yml,aws_api.yml" # Removed space for cleaner handling

      test_name:
        description: "Optional test name (blank = auto-generated)"
        required: false
        default: ""

      run_name:
        description: "Optional run name (blank = auto-generated)"
        required: false
        default: ""

      monitor_system:
        description: "Enable runner CPU/memory monitoring during tests?"
        required: false
        type: choice
        options:
          - "true"
          - "false"
        default: "false"

      cleanup_days:
        description: "Delete reports/artifacts older than X days (used in cleanup mode)"
        required: false
        default: "7"

      print_machine_info:
        description: "Print machine details before running?"
        required: false
        type: choice
        options:
          - "true"
          - "false"
        default: "false"

# ============================================================
# Global environment variables used throughout all jobs
# ============================================================
env:
  ARTILLERY_VERSION: "2.0.21"
  UPLOAD_RESULTS: "true"
  SCRIPTS_DIR: "./applications/${{ github.event.inputs.app_name }}/scripts"
  DATA_DIR: "./applications/${{ github.event.inputs.app_name }}/data"

  # -------------------------------
  # Variables for Python script environment (Requirement 2)
  # -------------------------------
  PY_APP_NAME: ${{ github.event.inputs.app_name }}
  PY_TEST_NAME: ${{ github.event.inputs.test_name }}
  PY_RUN_ID: ${{ github.event.inputs.run_name }}
  PY_SLA: ""
  PY_MODE: ""
  PY_GRANULARITY: ""
  PY_SHOW_OVERALL_METRICS: ""


# ============================================================
# JOB 1: Set test name dynamically
# ============================================================
jobs:
  set-test-name:
    runs-on: ubuntu-latest
    outputs:
      final_test_name: ${{ steps.determine.outputs.final_test_name }}

    steps:
      - id: determine
        run: |
          # ----------------------------------------------------
          # Dynamically build the test name using inputs
          # ----------------------------------------------------
          DATE_MMDDYYYY=$(date +%m%d%Y)
          DATE_YYYYMMDD=$(date +%Y%m%d)
          BASE_NAME="artillery"

          # Construct name based on which inputs are given
          if [ -n "${{ github.event.inputs.test_name }}" ] && [ -n "${{ github.event.inputs.run_name }}" ]; then
            FINAL_NAME="${BASE_NAME}-${{ github.event.inputs.test_name }}-${{ github.event.inputs.run_name }}"
          elif [ -n "${{ github.event.inputs.test_name }}" ]; then
            FINAL_NAME="${BASE_NAME}-${{ github.event.inputs.test_name }}"
          elif [ -n "${{ github.event.inputs.run_name }}" ]; then
            FINAL_NAME="${BASE_NAME}-${{ github.event.inputs.run_name }}"
          else
            FINAL_NAME="${BASE_NAME}-test-${DATE_YYYYMMDD}-run_${DATE_MMDDYYYY}"
          fi

          echo "âœ… Final test name: $FINAL_NAME"
          echo "final_test_name=$FINAL_NAME" >> $GITHUB_OUTPUT

# ============================================================
# JOB 2: Run Artillery tests in parallel (if test_type == load)
# ============================================================
  run-artillery:
    if: ${{ github.event.inputs.test_type == 'load' }}
    name: "Run Artillery Tests"
    runs-on: ubuntu-latest
    needs: set-test-name

    # Use environment-specific secrets/variables (test/prod)
    environment: ${{ github.event.inputs.environment_name }}

    strategy:
      fail-fast: false
      matrix:
        runner_index: [1, 2, 3, 4]

    steps:
      # -------------------------------
      # Set REPORT_DIR using the output from the set-test-name job
      # -------------------------------
      - name: Set job environment variables
        id: set_env
        run: |
          # Set REPORT_DIR and ensure the folder exists
          REPORT_DIR="${{ github.workspace }}/_reports"
          mkdir -p "$REPORT_DIR"
          echo "REPORT_DIR=$REPORT_DIR" >> $GITHUB_ENV
          echo "REPORT_DIR location: $REPORT_DIR"

      # -----------------------------
      # Skip unused runners
      # -----------------------------
      - name: Skip Unused Runner
        if: ${{ matrix.runner_index > fromJSON(github.event.inputs.runners_to_use) }}
        run: |
          echo "Skipping runner ${{ matrix.runner_index }}"
          exit 0

      # -----------------------------
      # Checkout source code
      # -----------------------------
      - uses: actions/checkout@v4

      # -----------------------------
      # Optional: Print runner details
      # -----------------------------
      - name: Print Machine Info
        if: ${{ github.event.inputs.print_machine_info == 'true' }}
        run: |
          echo "===== Machine Info ====="
          nproc
          free -h
          uname -a
          echo "========================"

      # -------------------------------
      # Setup Python environment
      # -------------------------------
      - name: Setup Python
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        uses: actions/setup-python@v5
        with:
          python-version: "3.11" # Changed from 3.13.1 (pre-release) to stable 3.11

      # -------------------------------
      # Install Python dependencies
      # -------------------------------
      - name: Install Python Dependencies
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        run: |
          python -m pip install --upgrade pip
          pip install pandas plotly numpy pyyaml

      # -------------------------------
      # Install system utilities for monitoring
      # -------------------------------
      - name: Install system monitoring utilities (sysstat)
        if: ${{ github.event.inputs.monitor_system == 'true' && matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        run: sudo apt-get update && sudo apt-get install -y sysstat

      # -------------------------------
      # Ensure scenario YAML exists
      # -------------------------------
      - name: Check scenario YAML exists
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        shell: bash
        run: |
          # Split the input string by comma and take the first item to check its existence.
          SCENARIO_FILE=$(echo "${{ github.event.inputs.scenario_file }}" | awk -F ',' '{print $1}' | xargs)
          FULL_PATH="${{ env.SCRIPTS_DIR }}/$SCENARIO_FILE"

          if [ ! -f "$FULL_PATH" ]; then
            echo "::error file=$FULL_PATH::Scenario file not found: $FULL_PATH"
            exit 1
          else
            echo "Found primary scenario file: $FULL_PATH"
          fi

      # -----------------------------
      # Setup Node.js environment
      # -----------------------------
      - name: Setup Node.js
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        uses: actions/setup-node@v4
        with:
          node-version: 20

      # -----------------------------
      # Install Artillery globally and dependencies
      # -----------------------------
      - name: Install Artillery and Node Dependencies
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        run: |
          npm install -g artillery@${{ env.ARTILLERY_VERSION }}
          # Install Node dependencies needed by test scripts
          npm install aws4 @faker-js/faker csv-parse
          npm install --save-dev artillery-plugin-metrics-by-endpoint
          artillery --version

      # -------------------------------
      # Optional System Monitoring
      # -------------------------------
      - name: Start system monitoring (optional)
        if: ${{ github.event.inputs.monitor_system == 'true' && matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        shell: bash
        run: |
          mkdir -p "${{ env.REPORT_DIR }}"
          LOG_FILE="${{ env.REPORT_DIR }}/runner-${{ matrix.runner_index }}-system.log"
          echo "timestamp,cpu_user,cpu_system,cpu_idle,mem_used,mem_free" > $LOG_FILE
          # Note: mpstat is used here to get CPU usage
          monitor() {
            while true; do
              ts=$(date +"%Y-%m-%d %H:%M:%S")
              # Get CPU stats (user, system, idle)
              cpu=$(mpstat 1 1 | awk '/Average/ {print $3","$5","$12}')
              # Get Memory stats (used, free in MB)
              mem=$(free -m | awk '/Mem:/ {print $3","$4}')
              echo "$ts,$cpu,$mem" >> $LOG_FILE
              sleep 180 # Log every 3 minutes
            done
          }
          monitor &
          echo $! > /tmp/monitor_pid.txt
          echo "System monitoring started in background, logging every 3 minutes."

      # -----------------------------
      # Map Environment Variables
      # -----------------------------
      - name: Map Environment Variables Dynamically
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        shell: bash
        env:
          # Use vars context to retrieve dynamic variables based on app_name input
          APP_BASE_URL: ${{ vars[format('{0}_BASE_URL', github.event.inputs.app_name)] }}
          APP_TARGET_HOST: ${{ vars[format('{0}_TARGET_HOST', github.event.inputs.app_name)] }}
          APP_REGION: ${{ vars[format('{0}_REGION', github.event.inputs.app_name)] }}
          # Use secrets context to retrieve dynamic secrets
          APP_ACCESS_KEY: ${{ secrets[format('{0}_ACCESS_KEY', github.event.inputs.app_name)] }}
          APP_SECRET_KEY: ${{ secrets[format('{0}_SECRET_KEY', github.event.inputs.app_name)] }}
          APP_UPPER: ${{ github.event.inputs.app_name }} # Pass app_name to the shell
        run: |
          # Convert app_name input to uppercase (e.g., "app1" -> "APP1")
          APP_UPPER=$(echo "$APP_UPPER" | tr '[:lower:]' '[:upper:]')

          # Export values to GitHub Actions environment for subsequent steps
          echo "BASE_URL=$APP_BASE_URL" >> $GITHUB_ENV
          echo "TARGET_HOST=$APP_TARGET_HOST" >> $GITHUB_ENV
          echo "AWS_REGION=$APP_REGION" >> $GITHUB_ENV
          echo "AWS_ACCESS_KEY_ID=$APP_ACCESS_KEY" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=$APP_SECRET_KEY" >> $GITHUB_ENV # NOTE: GitHub automatically masks secrets in logs

          echo "âœ… Environment variables mapped for $APP_UPPER"
          echo "BASE_URL=$APP_BASE_URL"
          echo "TARGET_HOST=$APP_TARGET_HOST"
          echo "REGION=$APP_REGION"

      # -----------------------------
      # Run Artillery Test
      # -----------------------------
      - name: Run Artillery Test
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        id: run_test
        shell: bash
        env:
          AUTH_HEADER: ${{ secrets.AUTH_HEADER }}
        run: |
          mkdir -p "${{ env.REPORT_DIR }}"

          JSON_OUT="${{ env.REPORT_DIR }}/result-runner-${{ matrix.runner_index }}.json"
          HTML_OUT="${{ env.REPORT_DIR }}/report-runner-${{ matrix.runner_index }}.html"

          echo "JSON_OUT : $JSON_OUT"
          echo "HTML_OUT : $HTML_OUT"

          # Pass environment variables to Artillery run command
          BASE_URL="$BASE_URL" \
          API_KEY="$API_KEY" \
          TARGET_HOST="$TARGET_HOST" \
          AUTH_HEADER="$AUTH_HEADER" \
          AWS_REGION="$AWS_REGION" \
          AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID" \
          AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY" \
          npx artillery run "applications/${{ github.event.inputs.app_name }}/scripts/${{ github.event.inputs.scenario_file }}" \
            --output "$JSON_OUT"

          npx artillery report "$JSON_OUT" --output "$HTML_OUT"
          echo "âœ… Artillery reports generated at: ${{ env.REPORT_DIR }}"

      # -------------------------------
      # Stop system monitoring (optional)
      # -------------------------------
      - name: Stop system monitoring (optional)
        if: ${{ github.event.inputs.monitor_system == 'true' && matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        shell: bash
        run: |
          if [ -f /tmp/monitor_pid.txt ]; then
            # Use '|| true' to prevent failure if process is already gone
            kill $(cat /tmp/monitor_pid.txt) || true
            rm /tmp/monitor_pid.txt
            echo "System monitoring stopped."
          fi
      
      # -------------------------------
      # Upload system monitoring logs (optional)
      # -------------------------------
      - name: Upload system monitoring logs (optional)
        if: ${{ github.event.inputs.monitor_system == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: runner-${{ matrix.runner_index }}-system-logs
          path: ${{ env.REPORT_DIR }}/runner-${{ matrix.runner_index }}-system.log

      # -------------------------------
      # Generate Python dashboard for this runner
      # -------------------------------
      - name: Generate Python dashboard for this runner
        if: ${{ matrix.runner_index <= fromJSON(github.event.inputs.runners_to_use) }}
        continue-on-error: true
        shell: bash
        run: |
          DASHBOARD_HTML="${{ env.REPORT_DIR }}/dashboard-runner-${{ matrix.runner_index }}.html"
          JSON_FILE="${{ env.REPORT_DIR }}/result-runner-${{ matrix.runner_index }}.json"
          echo "ðŸ“Š Generating Python dashboard for runner ${{ matrix.runner_index }}..."

          ARGS=""
          [ -n "${{ env.PY_APP_NAME }}" ] && ARGS="$ARGS --app-name \"${{ env.PY_APP_NAME }}\""
          [ -n "${{ env.PY_TEST_NAME }}" ] && ARGS="$ARGS --test-name \"${{ env.PY_TEST_NAME }}\""
          [ -n "${{ env.PY_SLA }}" ] && ARGS="$ARGS --sla \"${{ env.PY_SLA }}\""
          [ -n "${{ env.PY_MODE }}" ] && ARGS="$ARGS --mode \"${{ env.PY_MODE }}\""
          [ -n "${{ env.PY_GRANULARITY }}" ] && ARGS="$ARGS --granularity \"${{ env.PY_GRANULARITY }}\""
          # PY_SHOW_OVERALL_METRICS is not used as a value, only as a flag check
          if [ "${{ env.PY_SHOW_OVERALL_METRICS }}" = "true" ]; then ARGS="$ARGS --show-overall-metrics"; fi
          
          python "${GITHUB_WORKSPACE}/utilities/generate_artillery_dashboard.py" \
            --json "$JSON_FILE" \
            --yaml "${{ env.SCRIPTS_DIR }}/${{ github.event.inputs.scenario_file }}" \
            --output "$DASHBOARD_HTML" \
            $ARGS || echo "âš ï¸ Python dashboard generation failed for runner ${{ matrix.runner_index }}"
          
          echo "âœ… Dashboard generated: $DASHBOARD_HTML"

      # -------------------------------
      # Package all runner results into ZIP
      # -------------------------------
      - name: Package runner results
        if: always()
        shell: bash
        run: |
          ZIP_NAME="runner-${{ matrix.runner_index }}-results.zip"
          mkdir -p upload
          zip -r "upload/$ZIP_NAME" "${{ env.REPORT_DIR }}" >/dev/null || echo "âš ï¸ ZIP packaging warning"
          echo "âœ… Packaged runner ZIP: upload/$ZIP_NAME"

      # -------------------------------
      # Upload runner artifact
      # -------------------------------
      - name: Upload runner artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: artillery-results-runner-${{ matrix.runner_index }}
          path: upload/runner-${{ matrix.runner_index }}-results.zip
        continue-on-error: true

# ============================================================
# JOB 3: Aggregate results after all runners finish
# ============================================================
  aggregate-reports:
    if: always()
    runs-on: ubuntu-latest
    needs: [set-test-name, run-artillery]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Collect runner artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./downloaded-artifacts

      - name: Unzip all runner results
        shell: bash
        run: |
          # Use find to locate all zip files and unzip them recursively into the same folder
          find ./downloaded-artifacts -name '*.zip' -exec unzip -o {} -d ./downloaded-artifacts/ \;
          echo "âœ… Successfully unzipped all runner artifacts."

      - name: Merge all runner files into _reports
        shell: bash
        run: |
          REPORT_DIR="./_reports"
          mkdir -p "$REPORT_DIR"
          # Copy all files from unzipped artifacts into the consolidated report directory
          # The structure is: ./downloaded-artifacts/artillery-results-runner-N/upload/runner-N-results/result-runner-N.json
          # We need to use find to locate the actual report files inside the deep directory structure created by upload-artifact/download-artifact
          find ./downloaded-artifacts -type f \( -name 'result-runner-*.json' -o -name 'report-runner-*.html' -o -name 'dashboard-runner-*.html' -o -name 'runner-*-system.log' \) -exec cp {} "$REPORT_DIR" \;
          echo "âœ… Merged all runner files into $REPORT_DIR"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11" # Consistent Python version

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyyaml plotly numpy

      - name: Generate consolidated dashboard
        shell: bash
        run: |
          # Find all individual JSON files and join paths with a comma
          JSON_FILES=$(find ./_reports -name 'result-runner-*.json' -type f | paste -sd "," -)
          FINAL_HTML="./_reports/${{ needs.set-test-name.outputs.final_test_name }}-dashboard.html"
          
          if [ -n "$JSON_FILES" ]; then
            python "${GITHUB_WORKSPACE}/utilities/generate_artillery_dashboard.py" \
              --json "$JSON_FILES" \
              --yaml "${{ env.SCRIPTS_DIR }}/${{ github.event.inputs.scenario_file }}" \
              --output "$FINAL_HTML" || echo "âš ï¸ Consolidated dashboard failed"
            echo "âœ… Consolidated dashboard: $FINAL_HTML"
          else
            echo "âš ï¸ No JSON files found, skipping consolidated dashboard"
          fi

      - name: Package consolidated results
        shell: bash
        run: |
          zip -r consolidated-results.zip _reports >/dev/null
          echo "âœ… Packaged consolidated-results.zip"

      - name: Upload consolidated artifact
        uses: actions/upload-artifact@v4
        with:
          name: consolidated-artillery-results
          path: consolidated-results.zip


# ============================================================
# JOB 4: Cleanup (Only deletes old reports and artifacts)
# ============================================================
  cleanup-artifacts:
    if: ${{ github.event.inputs.test_type == 'cleanup' }}
    runs-on: ubuntu-latest
    steps:
      - name: Install JQ
        run: sudo apt-get update && sudo apt-get install -y jq

      # Removed 'Delete Old Local Reports' step as files are ephemeral on runners.

      - name: Delete Old GitHub Artifacts
        env:
          # Use the default GitHub Token for artifact deletion
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          DAYS=${{ github.event.inputs.cleanup_days }}
          REPO="${{ github.repository }}"
          API_URL="https://api.github.com/repos/$REPO/actions/artifacts?per_page=100"
          
          # Fetch all artifacts
          ARTIFACTS=$(curl -s -H "Authorization: token $GITHUB_TOKEN" "$API_URL" | jq -r '.artifacts[] | "\(.id) \(.created_at)"')
          
          NOW=$(date +%s)
          
          echo "Fetching and checking artifacts..."
          
          # Loop through artifacts and delete if older than $DAYS
          while read -r ID CREATED_AT; do
            ART_TS=$(date -d "$CREATED_AT" +%s)
            AGE=$(( (NOW - ART_TS) / 86400 ))
            
            if [ "$AGE" -gt "$DAYS" ]; then
              echo "Deleting artifact ID: $ID (created $CREATED_AT, $AGE days old)"
              
              # Execute deletion
              DELETE_URL="https://api.github.com/repos/$REPO/actions/artifacts/$ID"
              curl -s -X DELETE -H "Authorization: token $GITHUB_TOKEN" "$DELETE_URL" > /dev/null
            fi
          done <<< "$ARTIFACTS"
          
          echo "âœ… GitHub artifact cleanup completed (artifacts older than $DAYS days deleted)."
